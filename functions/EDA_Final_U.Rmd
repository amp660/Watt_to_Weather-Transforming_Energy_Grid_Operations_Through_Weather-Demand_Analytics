
---
title: "Weather-Energy Relationship Analysis"
subtitle: "Advanced Statistical Exploration and Modeling"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cosmo
    highlight: tango
    code_folding: show
date: "2025-05-05"
author: "Student Name"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


Executive Summary
This analysis explores the relationship between weather conditions and energy demand/consumption across various US regions. Using advanced statistical techniques, we identify a clear U-shaped relationship between temperature and energy demand, with increased consumption at both high and low temperature extremes. We quantify optimal temperature points, regional sensitivity variations, and economic implications of temperature deviations. The results provide actionable insights for energy providers, regulators, and consumers to optimize energy systems for changing weather patterns.

Key Findings:
U-Shaped Temperature-Demand Relationship: Energy demand follows a robust U-shaped pattern with temperature, minimizing at approximately 51.5°F.
Regional Variations: Weather sensitivity varies substantially by region, with ERCO (Texas) showing the highest elasticity to temperature changes.
Seasonal Effects: Summer demand exceeds winter by a significant margin, with clear statistical significance in seasonal patterns.
High Predictive Accuracy: Advanced modeling techniques achieve high accuracy in predicting energy demand based on weather variables.
Economic Implications: Each 1°F deviation from optimal temperature increases energy demand by approximately 2.03%.

```{r}
# 1. SETUP AND DATA PREPARATION
#------------------------------------------------------
# Load required libraries
library(tidyverse)      # Data manipulation and visualization
library(mgcv)           # For GAM modeling
library(lmtest)         # For hypothesis testing
library(car)            # For VIF analysis
library(quantreg)       # For quantile regression
library(segmented)      # For breakpoint analysis
library(Hmisc)          # For statistical tests
library(gridExtra)      # For grid plots
library(nlme)           # For mixed-effects models
library(sandwich)       # For robust standard errors
library(boot)           # For bootstrapping
library(performance)    # For model diagnostics
library(effects)        # For effect plots
library(MASS)           # For robust regression
library(corrplot)       # For correlation plots
library(viridis)        # For better color palettes
library(scales)         # For scale formatting
library(randomForest)   # For random forest models
library(gbm)            # For gradient boosting
library(caret)          # For model training and validation
library(patchwork)      # For combining plots
library(kableExtra)     # For pretty tables

# Record package versions for reproducibility
pkg_versions <- sapply(c("tidyverse", "mgcv", "lmtest", "car", "quantreg", "segmented", 
                        "nlme", "sandwich", "boot", "randomForest", "caret"), 
                      packageVersion)
pkg_versions_df <- data.frame(
  Package = names(pkg_versions),
  Version = as.character(pkg_versions)
)

# Display package versions
kable(pkg_versions_df, caption = "Package Versions") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Set seed for reproducibility
set.seed(123)

# Load the merged data
merged_data <- readRDS("../data/processed/merged_data.rds")

# Check the dimensions of the loaded data
cat("Loaded merged data with dimensions:", dim(merged_data), "\n")
cat("Date range:", min(merged_data$date), "to", max(merged_data$date), "\n")
cat("Number of locations:", n_distinct(merged_data$location), "\n")
cat("Number of energy regions:", n_distinct(merged_data$energy_region), "\n")
```

Data Cleaning and Transformation

```{r}
# 2. DATA CLEANING AND TRANSFORMATION
#------------------------------------------------------
# Convert value to numeric and add derived variables
merged_data <- merged_data %>%
  mutate(
    # Convert energy value to numeric
    energy_value = as.numeric(value),
    
    # Create time-based variables
    month = month(date, label = TRUE),
    season = case_when(
      month %in% c("Dec", "Jan", "Feb") ~ "Winter",
      month %in% c("Mar", "Apr", "May") ~ "Spring",
      month %in% c("Jun", "Jul", "Aug") ~ "Summer",
      month %in% c("Sep", "Oct", "Nov") ~ "Fall"
    ),
    weekday = wday(date, label = TRUE),
    is_weekend = weekday %in% c("Sat", "Sun"),
    
    # Create temperature bins for categorical analysis
    temp_bin = cut(temp_mean, 
                  breaks = seq(0, 100, by = 10),
                  labels = paste0(seq(0, 90, by = 10), "-", seq(10, 100, by = 10), "°F")),
    
    # Create humidity bins
    humidity_bin = cut(humidity_mean,
                      breaks = seq(0, 100, by = 20),
                      labels = paste0(seq(0, 80, by = 20), "-", seq(20, 100, by = 20), "%"))
  )

# Check for missing values
missing_summary <- merged_data %>%
  summarise(across(everything(), ~sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "Variable", values_to = "Missing_Count") %>%
  filter(Missing_Count > 0) %>%
  arrange(desc(Missing_Count)) %>%
  mutate(Missing_Percent = Missing_Count / nrow(merged_data) * 100)

# Display missing values summary
if(nrow(missing_summary) > 0) {
  kable(missing_summary, caption = "Missing Values Summary") %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
} else {
  cat("No missing values found in the dataset.")
}

# Create demand-focused dataset for analysis
demand_data <- merged_data %>%
  filter(type == "D") %>%  # Focus on demand data
  filter(!is.na(energy_value), !is.na(temp_mean)) %>%  # Remove missing values
  mutate(
    temp_squared = temp_mean^2,  # Quadratic term for U-shape
    temp_centered = scale(temp_mean, scale = FALSE),  # Centered temp for easier interpretation
    temp_centered_squared = temp_centered^2,
    log_energy = log(energy_value),
    
    # Additional derived variables for advanced analysis
    temp_cubic = temp_mean^3,  # Cubic term for potential asymmetry
    temp_humidity_interaction = temp_mean * humidity_mean,  # Interaction term
    heat_index = case_when(
      temp_mean >= 80 & humidity_mean >= 40 ~ 
        -42.379 + 2.04901523 * temp_mean + 10.14333127 * humidity_mean - 
        0.22475541 * temp_mean * humidity_mean - 0.00683783 * temp_mean^2 - 
        0.05481717 * humidity_mean^2 + 0.00122874 * temp_mean^2 * humidity_mean + 
        0.00085282 * temp_mean * humidity_mean^2 - 0.00000199 * temp_mean^2 * humidity_mean^2,
      TRUE ~ temp_mean  # Use regular temperature if heat index conditions not met
    )
  )

# Verify demand data creation
cat("Created demand dataset with dimensions:", dim(demand_data), "\n")
cat("Covering", n_distinct(demand_data$energy_region), "energy regions\n")
cat("Temperature range:", min(demand_data$temp_mean), "to", max(demand_data$temp_mean), "°F\n")
```

Descriptive Statistics

```{r}
# 3. DESCRIPTIVE STATISTICS
#------------------------------------------------------
# Calculate summary statistics by region and season
summary_stats <- demand_data %>%
  group_by(energy_region, season) %>%
  summarise(
    n_obs = n(),
    mean_demand = mean(energy_value, na.rm = TRUE),
    median_demand = median(energy_value, na.rm = TRUE),
    sd_demand = sd(energy_value, na.rm = TRUE),
    min_demand = min(energy_value, na.rm = TRUE),
    max_demand = max(energy_value, na.rm = TRUE),
    mean_temp = mean(temp_mean, na.rm = TRUE),
    temp_range = max(temp_mean, na.rm = TRUE) - min(temp_mean, na.rm = TRUE),
    temp_sd = sd(temp_mean, na.rm = TRUE),
    cv_demand = sd_demand / mean_demand * 100,  # Coefficient of variation
    .groups = 'drop'
  ) %>%
  arrange(energy_region, season)

# Display summary statistics
kable(head(summary_stats, 8), 
     caption = "Summary Statistics by Region and Season (First 8 rows)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), font_size = 12)

# Create a heatmap of average demand by region and season
demand_heatmap <- ggplot(summary_stats, 
                        aes(x = season, y = reorder(energy_region, mean_demand), 
                            fill = mean_demand)) +
  geom_tile() +
  scale_fill_viridis(option = "plasma", name = "Mean Demand") +
  labs(
    title = "Average Energy Demand by Region and Season",
    subtitle = "Higher values indicate greater energy consumption",
    x = "Season",
    y = "Energy Region"
  ) +
  theme_minimal() +
  theme(legend.position = "right")

print(demand_heatmap)
```

Distribution Analysis

```{r}
# 4. DISTRIBUTION ANALYSIS
#------------------------------------------------------
# Energy value distribution by type
energy_dist_plot <- ggplot(merged_data %>% filter(type %in% c("D", "NG")), 
                           aes(x = energy_value/1000, fill = type)) +
  geom_histogram(bins = 50, alpha = 0.7, position = "dodge") +
  scale_x_log10(labels = comma) +
  scale_fill_brewer(palette = "Set1", 
                    labels = c("D" = "Demand", "NG" = "Net Generation")) +
  labs(
    title = "Distribution of Energy Values by Type",
    subtitle = "Log scale to show full range",
    x = "Energy Value (GWh)",
    y = "Count",
    fill = "Energy Type",
    caption = "Note: Log scale used due to wide range of values"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    legend.position = "bottom"
  )

print(energy_dist_plot)
ggsave("output/figures/energy_distribution.png", energy_dist_plot, 
       width = 10, height = 6, dpi = 300)

# Create QQ plots to check for normality
qq_plot <- demand_data %>%
  ggplot(aes(sample = energy_value)) +
  stat_qq() +
  stat_qq_line() +
  facet_wrap(~ energy_region, scales = "free") +
  labs(
    title = "QQ Plots of Energy Demand by Region",
    subtitle = "Checking for normality of distribution",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_minimal()

print(qq_plot)
```

U-Shaped Relationship Analysis

```{r}
# 5. U-SHAPED RELATIONSHIP ANALYSIS
#------------------------------------------------------
# 5.1 Visualization of U-shape
u_shape_plot <- ggplot(demand_data, aes(x = temp_mean, y = energy_value/1000)) +
  geom_hex(bins = 50) +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), 
              color = "red", size = 1.5) +
  scale_fill_viridis(option = "plasma", trans = "log10") +
  labs(
    title = "U-Shaped Relationship: Temperature vs Energy Demand",
    subtitle = "Higher demand at both temperature extremes",
    x = "Average Temperature (°F)",
    y = "Energy Demand (GWh)",
    fill = "Count\n(log scale)",
    caption = "Data source: Merged weather and energy dataset (2024)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    legend.position = "right"
  )

print(u_shape_plot)
ggsave("output/figures/u_shape_relationship.png", u_shape_plot, 
       width = 10, height = 8, dpi = 300)

# 5.2 Seasonal Temperature vs Demand
temp_demand_plot <- ggplot(demand_data, 
                          aes(x = temp_mean, y = energy_value/1000)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_smooth(method = "loess", color = "red", size = 1.2) +
  facet_wrap(~ season, scales = "free_y") +
  labs(
    title = "Temperature vs Energy Demand by Season",
    subtitle = "Non-linear relationship evident in extreme temperatures",
    x = "Average Temperature (°F)",
    y = "Energy Demand (GWh)",
    caption = "Blue points: individual observations; Red line: LOESS smoothed trend"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    strip.background = element_rect(fill = "gray90"),
    strip.text = element_text(size = 12, face = "bold")
  )

print(temp_demand_plot)
ggsave("output/figures/temp_demand_by_season.png", temp_demand_plot, 
       width = 12, height = 8, dpi = 300)

# 5.3 Publication-ready U-shaped relationship
publication_plot <- ggplot(demand_data, aes(x = temp_mean, y = energy_value/1000)) +
  geom_point(alpha = 0.1, color = "gray40", size = 1) +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), 
              color = "#E31A1C", size = 1.5, se = TRUE, alpha = 0.2) +
  geom_vline(xintercept = c(40, 80), linetype = "dashed", color = "darkred") +
  annotate("text", x = 30, y = max(demand_data$energy_value/1000) * 0.9, 
           label = "Heating\nDemand", color = "darkred", size = 5) +
  annotate("text", x = 90, y = max(demand_data$energy_value/1000) * 0.9, 
           label = "Cooling\nDemand", color = "darkred", size = 5) +
  annotate("text", x = 60, y = min(demand_data$energy_value/1000) * 1.1, 
           label = "Optimal\nTemperature\nRange", color = "darkgreen", size = 5) +
  labs(
    title = "The U-Shaped Relationship Between Temperature and Energy Demand",
    subtitle = "Evidence of heating and cooling thresholds in energy consumption",
    x = "Average Daily Temperature (°F)",
    y = "Energy Demand (GWh)",
    caption = "Source: 2024 Weather and Energy Data Analysis"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    plot.subtitle = element_text(size = 14),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.grid.minor = element_blank()
  )

print(publication_plot)
ggsave("output/figures/publication_u_shape.png", publication_plot, 
       width = 12, height = 8, dpi = 300)

# 5.4 Quadratic Model for U-Shape Verification
quad_model <- lm(energy_value ~ temp_mean + temp_squared, data = demand_data)
quad_summary <- summary(quad_model)

# Display model results in a formatted table
quad_coefficients <- data.frame(
  Parameter = rownames(coef(summary(quad_model))),
  Estimate = coef(summary(quad_model))[,1],
  Std_Error = coef(summary(quad_model))[,2],
  t_value = coef(summary(quad_model))[,3],
  p_value = coef(summary(quad_model))[,4]
)

kable(quad_coefficients, caption = "Quadratic Regression Model Results", digits = 4) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  row_spec(3, background = "#f5f5f5")  # Highlight the quadratic term

# Extract key statistics
model_statistics <- data.frame(
  Statistic = c("R-squared", "Adjusted R-squared", "F-statistic", "p-value", "Residual std error", "Observations"),
  Value = c(
    quad_summary$r.squared,
    quad_summary$adj.r.squared,
    quad_summary$fstatistic[1],
    pf(quad_summary$fstatistic[1], quad_summary$fstatistic[2], quad_summary$fstatistic[3], lower.tail = FALSE),
    sqrt(mean(quad_model$residuals^2)),
    nrow(demand_data)
  )
)

kable(model_statistics, caption = "Model Statistics", digits = 4) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 5.5 Calculate optimal temperature (inflection point)
optimal_temp <- -coef(quad_model)[2] / (2 * coef(quad_model)[3])
cat(paste("Optimal Temperature (Inflection Point):", round(optimal_temp, 2), "°F\n"))

# 5.6 Bootstrap Confidence Intervals for Inflection Point
boot_inflection <- function(data, indices) {
  boot_data <- data[indices, ]
  boot_model <- lm(energy_value ~ temp_mean + temp_squared, data = boot_data)
  -coef(boot_model)[2] / (2 * coef(boot_model)[3])
}

# Run bootstrap with progress indicator
cat("Running bootstrap for confidence intervals...\n")
boot_results <- boot(data = demand_data, statistic = boot_inflection, R = 1000)
inflection_ci <- boot.ci(boot_results, type = "perc")

# Format bootstrap results
bootstrap_ci <- data.frame(
  Parameter = "Optimal Temperature",
  Point_Estimate = optimal_temp,
  Lower_CI_95 = inflection_ci$percent[4],
  Upper_CI_95 = inflection_ci$percent[5],
  Bootstrap_Replicates = 1000
)

kable(bootstrap_ci, caption = "Bootstrap Confidence Interval for Optimal Temperature", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 5.7 Non-parametric validation of U-shape using GAM
gam_model <- gam(energy_value ~ s(temp_mean, bs = "cs"), data = demand_data)
gam_summary <- summary(gam_model)

# Format GAM results
gam_results <- data.frame(
  Model = "Generalized Additive Model",
  Effective_DF = round(gam_summary$edf, 2),
  R_squared = gam_summary$r.sq,
  Deviance_explained = gam_summary$dev.expl * 100,
  GCV = gam_summary$sp.criterion
)

kable(gam_results, caption = "GAM Model Results (Non-parametric Validation)", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 5.8 Segmented regression to identify breaking points
seg_model <- segmented(lm(energy_value ~ temp_mean, data = demand_data), 
                      seg.Z = ~temp_mean, psi = c(40, 70))
seg_summary <- summary(seg_model)

# Extract breakpoints and their confidence intervals
breakpoints <- data.frame(
  Breakpoint = c("Lower breakpoint", "Upper breakpoint"),
  Estimate = c(seg_model$psi[1,1], seg_model$psi[2,1]),
  Std_Error = c(seg_model$psi[1,2], seg_model$psi[2,2]),
  CI_Lower = c(confint(seg_model)[1,1], confint(seg_model)[2,1]),
  CI_Upper = c(confint(seg_model)[1,2], confint(seg_model)[2,2])
)

kable(breakpoints, caption = "Temperature Breakpoints from Segmented Regression", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 5.9 Quantile regression to examine relationship across different demand levels
quantiles <- c(0.1, 0.25, 0.5, 0.75, 0.9)
quant_results <- data.frame()

for (q in quantiles) {
  quant_model <- rq(energy_value ~ temp_mean + temp_squared, tau = q, data = demand_data)
  quant_summary <- summary(quant_model)
  
  # Store results
  quant_results <- rbind(quant_results, data.frame(
    quantile = q,
    coef_temp = coef(quant_model)[2],
    coef_temp_squared = coef(quant_model)[3],
    optimal_temp = -coef(quant_model)[2] / (2 * coef(quant_model)[3])
  ))
}

kable(quant_results, caption = "Quantile Regression Results (U-shape across demand percentiles)", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Visualize optimal temperature across quantiles
quant_plot <- ggplot(quant_results, aes(x = quantile, y = optimal_temp)) +
  geom_line(size = 1, color = "steelblue") +
  geom_point(size = 3, color = "steelblue") +
  geom_hline(yintercept = optimal_temp, linetype = "dashed", color = "red") +
  annotate("text", x = 0.8, y = optimal_temp + 1, 
           label = paste("Mean Optimal:", round(optimal_temp, 1), "°F"), 
           color = "red") +
  labs(
    title = "Optimal Temperature Across Demand Quantiles",
    subtitle = "Examining if the U-curve inflection point varies by demand level",
    x = "Demand Quantile",
    y = "Optimal Temperature (°F)"
  ) +
  theme_minimal()

print(quant_plot)
ggsave("output/figures/optimal_temp_quantiles.png", quant_plot, 
       width = 8, height = 6, dpi = 300)
```

Regional Sensitivity Analysis

```{r}
# 6. REGIONAL SENSITIVITY ANALYSIS
#------------------------------------------------------
# 6.1 Calculate temperature elasticity of demand by region
elasticity_data <- demand_data %>%
  filter(temp_mean > optimal_temp) %>%  # Focus on cooling region of U-curve
  group_by(energy_region) %>%
  summarise(
    elasticity = cov(log(energy_value), log(temp_mean)) / var(log(temp_mean)),
    r_squared = cor(log(energy_value), log(temp_mean))^2,
    p_value = cor.test(log(energy_value), log(temp_mean))$p.value,
    n_obs = n(),
    mean_temp = mean(temp_mean),
    mean_demand = mean(energy_value),
    .groups = 'drop'
  ) %>%
  arrange(desc(elasticity))

kable(elasticity_data, caption = "Temperature Elasticity by Region", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  row_spec(which(elasticity_data$elasticity == max(elasticity_data$elasticity)), 
          background = "#f5f5f5", bold = TRUE)

# 6.2 Regional sensitivity visualization
regional_sensitivity <- demand_data %>%
  group_by(energy_region) %>%
  summarise(
    weather_sensitivity = cor(temp_mean, energy_value, use = "complete.obs"),
    avg_demand = mean(energy_value/1000),
    demand_volatility = sd(energy_value/1000),
    temp_range = max(temp_mean) - min(temp_mean),
    n_obs = n(),
    .groups = 'drop'
  ) %>%
  filter(!is.na(weather_sensitivity)) %>%
  mutate(
    # Calculate standard error for correlation
    se_correlation = sqrt((1 - weather_sensitivity^2) / (n_obs - 2)),
    # Calculate 95% confidence intervals
    ci_lower = weather_sensitivity - 1.96 * se_correlation,
    ci_upper = weather_sensitivity + 1.96 * se_correlation
  )

sensitivity_plot <- ggplot(regional_sensitivity, 
                          aes(x = reorder(energy_region, weather_sensitivity), 
                              y = weather_sensitivity)) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.8) +
  geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) +
  geom_text(aes(label = sprintf("%.3f", weather_sensitivity)), 
            vjust = -0.5, size = 3.5) +
  coord_flip() +
  labs(
    title = "Weather Sensitivity by Energy Region",
    subtitle = "Correlation between temperature and energy demand with 95% CI",
    x = "Energy Region",
    y = "Weather Sensitivity (Correlation Coefficient)",
    caption = "Higher values indicate stronger weather-demand relationship"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    plot.subtitle = element_text(size = 12),
    axis.title.y = element_text(margin = ggplot2::margin(r = 10))
  )

# 6.3 Mixed-effects model to analyze regional variations
# Subset to avoid memory issues with very large datasets
if(nrow(demand_data) > 10000) {
  cat("Subsetting data for mixed-effects model (large dataset)...\n")
  set.seed(123)
  mixed_model_data <- demand_data %>%
    group_by(energy_region) %>%
    sample_n(min(n(), 2000)) %>%
    ungroup()
} else {
  mixed_model_data <- demand_data
}

mixed_model <- lme(energy_value ~ temp_mean + temp_squared,
                  random = ~1 + temp_mean|energy_region,
                  data = mixed_model_data)
mixed_summary <- summary(mixed_model)

# Format mixed model results
mixed_fixed <- data.frame(
  Parameter = rownames(mixed_summary$tTable),
  Estimate = mixed_summary$tTable[,"Value"],
  Std_Error = mixed_summary$tTable[,"Std.Error"],
  t_value = mixed_summary$tTable[,"t-value"],
  p_value = mixed_summary$tTable[,"p-value"]
)

kable(mixed_fixed, caption = "Mixed-Effects Model: Fixed Effects", digits = 4) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 6.4 Extract random effects to quantify regional variability
random_effects <- as.data.frame(ranef(mixed_model))
random_effects$energy_region <- rownames(random_effects)

# Format for better display
random_effects_formatted <- random_effects %>%
  rename(
    Intercept_Adjustment = `(Intercept)`,
    Temp_Slope_Adjustment = temp_mean
  ) %>%
  select(energy_region, Intercept_Adjustment, Temp_Slope_Adjustment) %>%
  mutate(
    Total_Intercept = fixef(mixed_model)[1] + Intercept_Adjustment,
    Total_Temp_Slope = fixef(mixed_model)[2] + Temp_Slope_Adjustment
  ) %>%
  arrange(desc(Temp_Slope_Adjustment))

kable(head(random_effects_formatted, 6), caption = "Random Effects by Region (Top 6)", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 6.5 Region-specific models to compare slopes
# Select main regions for comparison
main_regions <- c("ERCO", "CISO", "NYIS", "PJM")

region_models <- demand_data %>%
  filter(energy_region %in% main_regions) %>%
  group_by(energy_region) %>%
  do(model = lm(energy_value ~ temp_mean + temp_squared, data = .))

# Extract coefficients for each region
region_coefficients <- region_models %>%
  mutate(
    temp_coef = coef(model)[2],
    temp_sq_coef = coef(model)[3],
    optimal_temp = -coef(model)[2] / (2 * coef(model)[3]),
    r_squared = summary(model)$r.squared
  )

# Remove the model column properly
region_coefficients$model <- NULL

kable(region_coefficients, caption = "Region-Specific Regression Coefficients", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Visualize region-specific U-curves
region_curves <- demand_data %>%
  filter(energy_region %in% main_regions) %>%
  ggplot(aes(x = temp_mean, y = energy_value/1000, color = energy_region)) +
  geom_smooth(method = "lm", formula = y ~ x + I(x^2), se = FALSE, size = 1.2) +
  geom_vline(data = region_coefficients, 
             aes(xintercept = optimal_temp, color = energy_region),
             linetype = "dashed") +
  labs(
    title = "Region-Specific U-Shaped Relationships",
    subtitle = "Temperature vs Energy Demand with Optimal Points",
    x = "Average Temperature (°F)",
    y = "Energy Demand (GWh)",
    color = "Energy Region"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

print(region_curves)
ggsave("output/figures/region_specific_curves.png", region_curves, 
       width = 10, height = 7, dpi = 300)

# 6.6 ANOVA with interaction effects to test regional differences
interaction_model <- lm(energy_value ~ temp_mean + temp_squared + energy_region + 
                       temp_mean:energy_region + temp_squared:energy_region,
                       data = demand_data %>% 
                         filter(energy_region %in% main_regions))
interaction_anova <- anova(interaction_model)

kable(interaction_anova, caption = "ANOVA Results for Regional Interaction Effects", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 6.7 Regional demand patterns visualization
regional_summary <- demand_data %>%
  group_by(energy_region, season) %>%
  summarise(
    avg_demand = mean(energy_value/1000, na.rm = TRUE),
    avg_temp = mean(temp_mean, na.rm = TRUE),
    weather_sensitivity = cor(temp_mean, energy_value, use = "complete.obs"),
    n_obs = n(),
    .groups = 'drop'
  ) %>%
  filter(!is.na(weather_sensitivity) & n_obs >= 30)  # Ensure sufficient observations

regional_plot <- ggplot(regional_summary, 
                       aes(x = avg_temp, y = avg_demand, 
                           color = energy_region, size = abs(weather_sensitivity))) +
  geom_point(alpha = 0.7) +
  facet_wrap(~ season) +
  scale_size_continuous(range = c(3, 10), name = "Weather\nSensitivity") +
  scale_color_viridis_d(option = "turbo") +
  labs(
    title = "Regional Energy Demand Patterns",
    subtitle = "Point size indicates weather sensitivity",
    x = "Average Temperature (°F)",
    y = "Average Demand (GWh)",
    color = "Energy Region",
    caption = "Data grouped by region and season; larger points show stronger temperature-demand correlation"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    legend.position = "right",
    legend.box = "vertical"
  )

print(regional_plot)
ggsave("output/figures/regional_patterns.png", regional_plot, 
       width = 12, height = 8, dpi = 300)
```

Seasonal Analysis

```{r}
# 7. SEASONAL ANALYSIS
#------------------------------------------------------
# 7.1 Test for statistical significance of seasonal differences
seasonal_model <- lm(energy_value ~ season, data = demand_data)
seasonal_anova <- anova(seasonal_model)

kable(seasonal_anova, caption = "ANOVA Results for Seasonal Differences", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 7.2 Post-hoc test to identify which seasons differ
seasonal_tukey <- TukeyHSD(aov(energy_value ~ season, data = demand_data))

seasonal_tukey_df <- as.data.frame(seasonal_tukey$season)
seasonal_tukey_df$comparison <- rownames(seasonal_tukey_df)

kable(seasonal_tukey_df, caption = "Pairwise Seasonal Comparisons (Tukey HSD)", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  row_spec(which(seasonal_tukey_df$`p adj` < 0.05), background = "#f5f5f5")

# 7.3 Seasonal effect sizes
seasonal_effects <- demand_data %>%
  group_by(season) %>%
  summarise(
    mean_demand = mean(energy_value),
    n_obs = n(),
    sd_demand = sd(energy_value),
    se_demand = sd_demand / sqrt(n_obs),
    ci_lower = mean_demand - 1.96 * se_demand,
    ci_upper = mean_demand + 1.96 * se_demand,
    .groups = 'drop'
  ) %>%
  mutate(
    effect_size = mean_demand / mean(mean_demand) - 1,  # Percentage deviation from overall mean
    percent_diff_from_min = mean_demand / min(mean_demand) - 1  # Percentage difference from minimum
  )

kable(seasonal_effects, caption = "Seasonal Effect Sizes", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Visualize seasonal effects
seasonal_effects_plot <- ggplot(seasonal_effects, 
                              aes(x = reorder(season, mean_demand), y = mean_demand/1000)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_errorbar(aes(ymin = ci_lower/1000, ymax = ci_upper/1000), width = 0.2) +
  geom_text(aes(label = sprintf("%.1f%%", percent_diff_from_min * 100)), 
            vjust = -0.5, size = 4) +
  labs(
    title = "Energy Demand by Season",
    subtitle = "With 95% confidence intervals and percent above minimum",
    x = "Season",
    y = "Mean Energy Demand (GWh)",
    caption = "Percentages show increase compared to the season with minimum demand"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.title.x = element_text(margin = ggplot2::margin(t = 10))
  )

# 7.4 Seasonal optimal temperatures
season_optima <- demand_data %>%
  group_by(season) %>%
  do(model = lm(energy_value ~ temp_mean + temp_squared, data = .)) %>%
  mutate(
    optimal_temp = -coef(model)[2] / (2 * coef(model)[3]),
    r_squared = summary(model)$r.squared,
    temp_coef = coef(model)[2],
    temp_sq_coef = coef(model)[3]
  )

# Remove the model column properly
season_optima$model <- NULL

kable(season_optima, caption = "Seasonal Optimal Temperatures", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 7.5 Seasonal patterns with confidence intervals
seasonal_ci <- demand_data %>%
  group_by(season, temp_category = cut(temp_mean, breaks = 10)) %>%
  summarise(
    mean_demand = mean(energy_value/1000),
    se_demand = sd(energy_value/1000) / sqrt(n()),
    n = n(),
    .groups = 'drop'
  ) %>%
  mutate(
    ci_lower = mean_demand - 1.96 * se_demand,
    ci_upper = mean_demand + 1.96 * se_demand,
    temp_mid = as.numeric(gsub("\\((.*),.*", "\\1", temp_category)) + 5
  ) %>%
  filter(!is.na(temp_mid))  # Remove any parsing errors

seasonal_ci_plot <- ggplot(seasonal_ci, aes(x = temp_mid, y = mean_demand, 
                                           color = season, fill = season)) +
  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), alpha = 0.2, color = NA) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  scale_color_brewer(palette = "Set1") +
  scale_fill_brewer(palette = "Set1") +
  labs(
    title = "Seasonal Energy Demand Patterns with Confidence Intervals",
    subtitle = "95% confidence intervals show uncertainty in estimates",
    x = "Temperature (°F)",
    y = "Average Energy Demand (GWh)",
    color = "Season",
    fill = "Season",
    caption = "Shaded regions represent 95% confidence intervals"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    legend.position = "bottom",
    panel.grid.minor = element_blank()
  )

print(seasonal_ci_plot)
ggsave("output/figures/seasonal_ci_patterns.png", seasonal_ci_plot, 
       width = 12, height = 8, dpi = 300)

# 7.6 Interaction between season and temperature
season_temp_model <- lm(energy_value ~ temp_mean + temp_squared + season + 
                       temp_mean:season + temp_squared:season, 
                       data = demand_data)
season_temp_anova <- anova(season_temp_model)

kable(season_temp_anova, caption = "ANOVA Results for Season-Temperature Interaction", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Visualize seasonal U-curves
seasonal_curves <- ggplot(demand_data, aes(x = temp_mean, y = energy_value/1000, color = season)) +
  geom_smooth(method = "lm", formula = y ~ x + I(x^2), se = FALSE, size = 1.2) +
  geom_vline(data = season_optima, 
             aes(xintercept = optimal_temp, color = season),
             linetype = "dashed") +
  scale_color_brewer(palette = "Set1") +
  labs(
    title = "Season-Specific U-Shaped Relationships",
    subtitle = "Temperature vs Energy Demand with Optimal Points",
    x = "Average Temperature (°F)",
    y = "Energy Demand (GWh)",
    color = "Season",
    caption = "Dashed lines indicate optimal temperature for each season"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

print(seasonal_curves)
ggsave("output/figures/seasonal_curves.png", seasonal_curves, 
       width = 10, height = 7, dpi = 300)
```

 Time Series Analysis

```{r}
# 8. TIME SERIES ANALYSIS
#------------------------------------------------------
# 8.1 Daily energy patterns
daily_patterns <- demand_data %>%
  group_by(date, energy_region) %>%
  summarise(
    total_demand = sum(energy_value, na.rm = TRUE) / 1000,
    avg_temp = mean(temp_mean, na.rm = TRUE),
    .groups = 'drop'
  )

# Focus on main energy regions for visualization clarity
main_regions <- c("ERCO", "CISO", "NYIS", "PJM")

time_series_plot <- ggplot(daily_patterns %>% 
                           filter(energy_region %in% main_regions), 
                          aes(x = date, y = total_demand)) +
  geom_line(aes(color = energy_region), size = 0.8) +
  facet_wrap(~ energy_region, scales = "free_y", ncol = 2) +
  scale_color_brewer(palette = "Set1") +
  labs(
    title = "Daily Energy Demand Patterns by Region",
    subtitle = "Seasonal variations and regional differences",
    x = "Date",
    y = "Total Daily Demand (GWh)",
    color = "Energy Region",
    caption = "Note the different y-axis scales for each region"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    legend.position = "none",
    strip.background = element_rect(fill = "gray90"),
    strip.text = element_text(size = 12, face = "bold")
  )

print(time_series_plot)
ggsave("output/figures/time_series_by_region.png", time_series_plot, 
       width = 12, height = 8, dpi = 300)

# Decompose time series for seasonal patterns
# Select a single region for clearer decomposition
if("ERCO" %in% unique(daily_patterns$energy_region)) {
  region_for_ts <- "ERCO"
} else {
  region_for_ts <- daily_patterns$energy_region[1]
}

ts_data <- daily_patterns %>%
  filter(energy_region == region_for_ts) %>%
  arrange(date)

# Create time series object if we have enough data
if(nrow(ts_data) >= 14) { # Need at least 2 weeks of data
  # Convert to time series object
  ts_energy <- ts(ts_data$total_demand, frequency = 7)  # Weekly seasonality
  
  # Decompose the time series
  decomp <- decompose(ts_energy)
  
  # Plot decomposition
  decomp_data <- data.frame(
    time = 1:length(decomp$x),
    observed = as.numeric(decomp$x),
    trend = as.numeric(decomp$trend),
    seasonal = as.numeric(decomp$seasonal),
    random = as.numeric(decomp$random)
  )
  
  # Create decomposition plot
  p1 <- ggplot(decomp_data, aes(x = time, y = observed)) + 
    geom_line() + 
    labs(title = "Observed", x = "Time", y = "Energy Demand (GWh)") +
    theme_minimal()
  
  p2 <- ggplot(decomp_data, aes(x = time, y = trend)) + 
    geom_line(color = "blue") + 
    labs(title = "Trend", x = "Time", y = "Energy Demand (GWh)") +
    theme_minimal()
  
  p3 <- ggplot(decomp_data, aes(x = time, y = seasonal)) + 
    geom_line(color = "red") + 
    labs(title = "Seasonal", x = "Time", y = "Energy Demand (GWh)") +
    theme_minimal()
  
  p4 <- ggplot(decomp_data, aes(x = time, y = random)) + 
    geom_line(color = "green") + 
    labs(title = "Random", x = "Time", y = "Energy Demand (GWh)") +
    theme_minimal()
  
  decomp_plot <- (p1 / p2 / p3 / p4) + 
    plot_annotation(
      title = paste("Time Series Decomposition for", region_for_ts, "Energy Region"),
      subtitle = "Weekly seasonality pattern",
      caption = "Data decomposed into trend, seasonal, and random components"
    )
  
  print(decomp_plot)
  ggsave("output/figures/time_series_decomposition.png", decomp_plot, 
         width = 10, height = 12, dpi = 300)
}
```

Correlation Analysis

```{r}
# 9. CORRELATION ANALYSIS
#------------------------------------------------------
# 9.1 Correlation matrix
cor_data <- demand_data %>%
  select(energy_value, temp_mean, temp_range, humidity_mean, 
         precipitation_total, wind_speed_mean, cloud_cover_mean) %>%
  na.omit()

cor_matrix <- cor(cor_data)

# Create correlation plot
png("output/figures/correlation_matrix.png", width = 800, height = 800)
corrplot(cor_matrix, 
         method = "color",
         type = "upper",
         order = "hclust",
         addCoef.col = "black",
         tl.col = "black",
         tl.srt = 45,
         diag = FALSE,
         title = "Correlation Matrix: Weather Variables vs Energy Demand",
         mar = c(0,0,2,0))
dev.off()

# Create a formatted correlation table
cor_table <- as.data.frame(cor_matrix)
cor_table$Variable <- rownames(cor_table)
cor_table <- cor_table %>%
  select(Variable, everything()) %>%
  mutate(across(where(is.numeric), ~round(., 3)))

kable(cor_table, caption = "Correlation Matrix of Weather and Energy Variables") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = TRUE)

# Scatter plot matrix of key variables
pairs_plot <- ggplot(cor_data %>% sample_n(min(5000, nrow(cor_data))), 
                    aes(x = temp_mean, y = energy_value/1000)) +
  geom_point(alpha = 0.5, size = 2, color = "steelblue") +
  geom_smooth(method = "loess", color = "red", se = FALSE) +
  facet_wrap(~ cut(humidity_mean, breaks = 4), scales = "free_y") +
  labs(
    title = "Energy Demand vs Temperature at Different Humidity Levels",
    subtitle = "Exploring interaction effects",
    x = "Average Temperature (°F)",
    y = "Energy Demand (GWh)",
    caption = "LOESS smoothed trend lines show temperature-demand relationship"
  ) +
  theme_minimal()

print(pairs_plot)
ggsave("output/figures/humidity_interaction_plot.png", pairs_plot, 
       width = 10, height = 8, dpi = 300)

# Partial correlation analysis
# Calculate partial correlation between temperature and energy, controlling for humidity
partial_cor <- cor(resid(lm(energy_value ~ humidity_mean, data = cor_data)),
                  resid(lm(temp_mean ~ humidity_mean, data = cor_data)))

partial_cor_df <- data.frame(
  Relationship = "Temperature ~ Energy (controlling for humidity)",
  Correlation = partial_cor,
  Raw_Correlation = cor(cor_data$temp_mean, cor_data$energy_value)
)

kable(partial_cor_df, caption = "Partial Correlation Analysis", digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

Predictive Modeling

```{r}
# 10. PREDICTIVE MODELING
#------------------------------------------------------
# 10.1 Prepare data for modeling
model_data <- demand_data %>%
  select(energy_value, temp_mean, temp_range, humidity_mean, 
         precipitation_total, wind_speed_mean, cloud_cover_mean,
         season, is_weekend, energy_region) %>%
  na.omit() %>%
  mutate(
    temp_squared = temp_mean^2,  # Add quadratic term for U-shape
    log_energy = log(energy_value),
    # Convert character variables to factors
    season = factor(season, levels = c("Winter", "Spring", "Summer", "Fall")),
    energy_region = factor(energy_region),
    is_weekend = factor(is_weekend)
  )

# Print basic data summary
cat(sprintf("Prepared modeling dataset with %d observations and %d variables\n", 
            nrow(model_data), ncol(model_data)))

# 10.2 Split data
set.seed(123)
train_index <- createDataPartition(model_data$energy_value, p = 0.8, list = FALSE)
train_data <- model_data[train_index, ]
test_data <- model_data[-train_index, ]

cat(sprintf("Training data size: %d\n", nrow(train_data)))
cat(sprintf("Test data size: %d\n", nrow(test_data)))

# 10.3 Linear Regression model
linear_model <- lm(energy_value ~ temp_mean + temp_squared + humidity_mean + 
                  wind_speed_mean + cloud_cover_mean + season + is_weekend + 
                  energy_region, 
                data = train_data)
linear_summary <- summary(linear_model)

# Format linear model results
linear_coefficients <- data.frame(
  Parameter = rownames(coef(summary(linear_model))),
  Estimate = coef(summary(linear_model))[,1],
  Std_Error = coef(summary(linear_model))[,2],
  t_value = coef(summary(linear_model))[,3],
  p_value = coef(summary(linear_model))[,4]
) %>%
  mutate(
    Significance = case_when(
      p_value < 0.001 ~ "***",
      p_value < 0.01 ~ "**",
      p_value < 0.05 ~ "*",
      p_value < 0.1 ~ ".",
      TRUE ~ ""
    )
  )

# Display only the key coefficients for brevity
key_coefficients <- linear_coefficients %>%
  filter(grepl("^temp|^humid|^season|^is_weekend|Intercept", Parameter)) %>%
  slice(1:10)  # Limit to first 10 rows for readability

kable(key_coefficients, 
     caption = "Linear Regression Model: Key Coefficients (first 10 rows only)", 
     digits = 4) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Summary statistics
linear_stats <- data.frame(
  Statistic = c("R-squared", "Adjusted R-squared", "F-statistic", "p-value", "Residual std error"),
  Value = c(
    linear_summary$r.squared, 
    linear_summary$adj.r.squared,
    linear_summary$fstatistic[1],
    pf(linear_summary$fstatistic[1], linear_summary$fstatistic[2], linear_summary$fstatistic[3], lower.tail = FALSE),
    sqrt(mean(linear_model$residuals^2))
  )
)

kable(linear_stats, caption = "Linear Model Summary Statistics", digits = 4) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)


# 10.5 Random Forest model
# Subsample for efficiency if dataset is very large
if(nrow(train_data) > 10000) {
  set.seed(123)
  rf_train_data <- train_data %>% sample_n(10000)
  cat("Using a subsample of 10,000 observations for Random Forest\n")
} else {
  rf_train_data <- train_data
}

rf_model <- randomForest(
  energy_value ~ temp_mean + temp_range + humidity_mean + 
  precipitation_total + wind_speed_mean + cloud_cover_mean + 
  season + is_weekend + energy_region,
  data = rf_train_data,
  ntree = 500,
  importance = TRUE
)

# Print basic RF model info
cat(sprintf("Random Forest model with %d trees\n", rf_model$ntree))
cat(sprintf("Variance explained: %.2f%%\n", rf_model$rsq[length(rf_model$rsq)] * 100))

# 10.6 Gradient Boosting model
gbm_model <- gbm(
  energy_value ~ temp_mean + temp_range + humidity_mean + 
  precipitation_total + wind_speed_mean + cloud_cover_mean + 
  season + is_weekend + energy_region,
  data = train_data,
  distribution = "gaussian",
  n.trees = 1000,
  interaction.depth = 4,
  shrinkage = 0.01,
  verbose = FALSE
)

# 10.7 Model Evaluation
# Predictions
linear_preds <- predict(linear_model, newdata = test_data)
rf_preds <- predict(rf_model, newdata = test_data)
gbm_preds <- predict(gbm_model, newdata = test_data, n.trees = 1000)

# Calculate metrics
calculate_metrics <- function(actual, predicted) {
  rmse <- sqrt(mean((actual - predicted)^2))
  mae <- mean(abs(actual - predicted))
  r_squared <- cor(actual, predicted)^2
  mape <- mean(abs((actual - predicted) / actual)) * 100
  
  return(c(rmse = rmse, mae = mae, r_squared = r_squared, mape = mape))
}

linear_metrics <- calculate_metrics(test_data$energy_value, linear_preds)
rf_metrics <- calculate_metrics(test_data$energy_value, rf_preds)
gbm_metrics <- calculate_metrics(test_data$energy_value, gbm_preds)

model_comparison <- data.frame(
  model = c("Linear Regression", "Random Forest", "Gradient Boosting"),
  rmse = c(linear_metrics["rmse"], rf_metrics["rmse"], gbm_metrics["rmse"]),
  mae = c(linear_metrics["mae"], rf_metrics["mae"], gbm_metrics["mae"]),
  r_squared = c(linear_metrics["r_squared"], rf_metrics["r_squared"], gbm_metrics["r_squared"]),
  mape = c(linear_metrics["mape"], rf_metrics["mape"], gbm_metrics["mape"]),
  percent_improvement = c(
    NA,
    (linear_metrics["rmse"] - rf_metrics["rmse"]) / linear_metrics["rmse"] * 100,
    (linear_metrics["rmse"] - gbm_metrics["rmse"]) / linear_metrics["rmse"] * 100
  )
)

kable(model_comparison, 
     caption = "Model Performance Comparison", 
     digits = c(0, 2, 2, 4, 2, 2)) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  row_spec(which.min(model_comparison$rmse), background = "#f5f5f5", bold = TRUE)

# 10.8 Variable importance
var_importance <- importance(rf_model)
var_importance_df <- data.frame(
  variable = rownames(var_importance),
  importance_mse = var_importance[, "%IncMSE"],
  importance_node_purity = var_importance[, "IncNodePurity"]
) %>%
  arrange(desc(importance_mse))

kable(var_importance_df, caption = "Variable Importance from Random Forest", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Create feature importance plot
importance_plot <- ggplot(var_importance_df, 
                         aes(x = reorder(variable, importance_mse), y = importance_mse)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Feature Importance in Energy Demand Prediction",
    subtitle = "Random Forest Model Results (%IncMSE)",
    x = "Variables",
    y = "Importance (%IncMSE)",
    caption = "Higher values indicate more important predictors"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"))

print(importance_plot)
ggsave("output/figures/feature_importance.png", importance_plot, 
       width = 10, height = 6, dpi = 300)

# Actual vs Predicted plot
prediction_data <- data.frame(
  Actual = test_data$energy_value / 1000,  # Convert to GWh
  Linear = linear_preds / 1000,
  RandomForest = rf_preds / 1000,
  GBM = gbm_preds / 1000
)

prediction_plot <- ggplot(prediction_data, aes(x = Actual, y = RandomForest)) +
  geom_point(alpha = 0.3, color = "steelblue") +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    title = "Random Forest: Actual vs Predicted Energy Demand",
    subtitle = paste("R² =", round(rf_metrics["r_squared"], 4)),
    x = "Actual Energy Demand (GWh)",
    y = "Predicted Energy Demand (GWh)",
    caption = "Dashed line represents perfect prediction"
  ) +
  theme_minimal()

print(prediction_plot)
ggsave("output/figures/actual_vs_predicted.png", prediction_plot, 
       width = 9, height = 7, dpi = 300)
```

Economic Implications

```{r}
# 11. ECONOMIC IMPLICATIONS
#------------------------------------------------------
# 11.1 Estimate marginal effect of 1°F deviation from optimal temperature
# Create a reference dataset at optimal temperature
optimal_temp_value <- optimal_temp

reference_data <- demand_data %>%
  filter(abs(temp_mean - optimal_temp_value) < 1) %>%
  summarise(baseline_demand = mean(energy_value))

baseline_demand <- reference_data$baseline_demand

cat(sprintf("Baseline demand at optimal temperature (%.2f°F): %.2f\n", 
            optimal_temp_value, baseline_demand))

  
# 11.2 Calculate percentage change in demand per degree F from optimal
temp_effect_data <- demand_data %>%
  mutate(
    deviation_from_optimal = abs(temp_mean - optimal_temp_value),
    deviation_category = cut(deviation_from_optimal, 
                           breaks = c(0, 5, 10, 15, 20, 25, 30, Inf),
                           labels = c("0-5°F", "5-10°F", "10-15°F", "15-20°F", 
                                     "20-25°F", "25-30°F", ">30°F"))
  ) %>%
  group_by(deviation_category) %>%
  summarise(
    mean_deviation = mean(deviation_from_optimal),
    mean_demand = mean(energy_value),
    median_demand = median(energy_value),
    pct_change = (mean_demand / baseline_demand - 1) * 100,
    pct_change_per_degree = pct_change / mean_deviation,
    n_obs = n(),
    .groups = 'drop'
  )

kable(temp_effect_data, caption = "Economic Impact per Degree F Deviation from Optimal Temperature", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  row_spec(which.max(temp_effect_data$pct_change_per_degree), background = "#f5f5f5")

# Visualize the economic impact
econ_impact_plot <- ggplot(temp_effect_data, 
                          aes(x = deviation_category, y = pct_change_per_degree)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = sprintf("%.2f%%", pct_change_per_degree)), 
            vjust = -0.5, size = 3.5) +
  labs(
    title = "Economic Impact of Temperature Deviations",
    subtitle = "Percentage increase in energy demand per degree F",
    x = "Deviation from Optimal Temperature",
    y = "% Increase in Demand per Degree F",
    caption = "Based on optimal temperature of 51.5°F"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

print(econ_impact_plot)
ggsave("output/figures/economic_impact.png", econ_impact_plot, 
       width = 10, height = 6, dpi = 300)

# 11.3 Create marginal effect curve using GAM model for smoother estimates
effect_model <- gam(energy_value ~ s(temp_mean, bs = "cs"), data = demand_data)

# Create prediction data
pred_temps <- seq(min(demand_data$temp_mean), max(demand_data$temp_mean), length.out = 100)
pred_data <- data.frame(temp_mean = pred_temps)

# Get predicted values
pred_vals <- predict(effect_model, newdata = pred_data, se.fit = TRUE)
pred_data$predicted_demand <- pred_vals$fit
pred_data$se_lower <- pred_vals$fit - 1.96 * pred_vals$se.fit
pred_data$se_upper <- pred_vals$fit + 1.96 * pred_vals$se.fit

# Calculate percentage change from optimal
optimal_pred_idx <- which.min(abs(pred_data$temp_mean - optimal_temp_value))
optimal_demand_pred <- pred_data$predicted_demand[optimal_pred_idx]

pred_data <- pred_data %>%
  mutate(
    deviation = abs(temp_mean - optimal_temp_value),
    pct_change = (predicted_demand / optimal_demand_pred - 1) * 100,
    pct_change_per_degree = ifelse(deviation > 0, pct_change / deviation, NA)
  )

# Create smooth curve plot
smooth_curve_plot <- ggplot(pred_data, aes(x = temp_mean)) +
  geom_ribbon(aes(ymin = se_lower, ymax = se_upper), alpha = 0.2, fill = "gray") +
  geom_line(aes(y = predicted_demand), size = 1.2, color = "blue") +
  geom_vline(xintercept = optimal_temp_value, linetype = "dashed", color = "red") +
  annotate("text", x = optimal_temp_value + 2, y = max(pred_data$predicted_demand) * 0.9,
           label = paste("Optimal Temp:", round(optimal_temp_value, 1), "°F"),
           color = "red", size = 4) +
  labs(
    title = "Smooth Energy Demand Curve with Confidence Intervals",
    subtitle = "GAM model predictions with 95% confidence bands",
    x = "Temperature (°F)",
    y = "Predicted Energy Demand",
    caption = "Dashed red line indicates optimal temperature"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(size = 16, face = "bold"))

print(smooth_curve_plot)
ggsave("output/figures/smooth_demand_curve.png", smooth_curve_plot, 
       width = 10, height = 6, dpi = 300)

# 11.4 Calculate marginal cost implications
# Create example data for cost implications (hypothetical)
avg_cost_per_unit <- 100  # Example cost in dollars per MWh

cost_implications <- temp_effect_data %>%
  mutate(
    baseline_cost = baseline_demand * avg_cost_per_unit,
    actual_cost = mean_demand * avg_cost_per_unit,
    cost_increase = actual_cost - baseline_cost,
    cost_increase_pct = (actual_cost / baseline_cost - 1) * 100,
    cost_increase_per_degree = cost_increase / mean_deviation
  ) %>%
  select(deviation_category, mean_deviation, baseline_cost, actual_cost, 
         cost_increase, cost_increase_pct, cost_increase_per_degree)

kable(cost_implications, 
     caption = "Hypothetical Cost Implications of Temperature Deviations ($100/MWh)", 
     digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

Statistical Robustness Checks

```{r}
# 12. STATISTICAL ROBUSTNESS CHECKS
#------------------------------------------------------
# 12.1 Heteroskedasticity test - Do residuals show uniform variance?
residuals <- resid(quad_model)
fitted_values <- fitted(quad_model)
bp_test <- bptest(quad_model)  # Breusch-Pagan test

bp_result <- data.frame(
  test_statistic = bp_test$statistic,
  p_value = bp_test$p.value,
  heteroskedasticity_present = bp_test$p.value < 0.05,
  interpretation = ifelse(bp_test$p.value < 0.05, 
                         "Residuals show non-constant variance (heteroskedasticity)",
                         "Residuals show constant variance (homoskedasticity)")
)

kable(bp_result, caption = "Heteroskedasticity Test (Breusch-Pagan)", digits = 4) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Residual plot
residual_plot <- ggplot(data.frame(fitted = fitted_values, residuals = residuals), 
                       aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.5, color = "steelblue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(method = "loess", se = FALSE, color = "darkred") +
  labs(
    title = "Residual Plot for Quadratic Model",
    subtitle = "Checking for non-constant variance",
    x = "Fitted Values",
    y = "Residuals",
    caption = "Dashed red line at zero; curved line shows trend in residuals"
  ) +
  theme_minimal()

print(residual_plot)
ggsave("output/figures/residual_plot.png", residual_plot, 
       width = 8, height = 6, dpi = 300)

# 12.2 Robust standard errors for quadratic model
robust_se <- sqrt(diag(vcovHC(quad_model, type = "HC1")))
robust_t <- coef(quad_model) / robust_se
robust_p <- 2 * pt(abs(robust_t), df = quad_model$df.residual, lower.tail = FALSE)

robust_results <- data.frame(
  coefficient = names(coef(quad_model)),
  estimate = coef(quad_model),
  std_error = robust_se,
  t_value = robust_t,
  p_value = robust_p,
  significant = robust_p < 0.05
)

kable(robust_results, caption = "Robust Standard Errors", digits = 4) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 12.3 Bootstrapped coefficients for quadratic model
set.seed(123)
boot_model <- function(data, indices) {
  boot_data <- data[indices, ]
  boot_fit <- lm(energy_value ~ temp_mean + temp_squared, data = boot_data)
  return(coef(boot_fit))
}

boot_results <- boot(data = demand_data, statistic = boot_model, R = 1000)
boot_ci_temp <- boot.ci(boot_results, type = "perc", index = 2)
boot_ci_temp_sq <- boot.ci(boot_results, type = "perc", index = 3)

boot_ci_results <- data.frame(
  coefficient = c("temp_mean", "temp_squared"),
  estimate = c(coef(quad_model)[2], coef(quad_model)[3]),
  boot_lower_ci = c(boot_ci_temp$percent[4], boot_ci_temp_sq$percent[4]),
  boot_upper_ci = c(boot_ci_temp$percent[5], boot_ci_temp_sq$percent[5]),
  significant = c(
    boot_ci_temp$percent[4] * boot_ci_temp$percent[5] > 0,
    boot_ci_temp_sq$percent[4] * boot_ci_temp_sq$percent[5] > 0
  )
)

kable(boot_ci_results, caption = "Bootstrap Confidence Interval Results", digits = 4) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# 12.4 Normality test for model residuals
# Check the length of residuals
residuals_length <- length(residuals)
cat(sprintf("Number of residuals: %d\n", residuals_length))

# If more than 5000 observations, take a random sample
if(length(residuals) > 5000) {
  set.seed(123) # For reproducibility
  residuals_sample <- sample(residuals, 5000)
  shapiro_test <- shapiro.test(residuals_sample)
  cat("Shapiro-Wilk test performed on a random sample of 5000 residuals\n")
} else {
  shapiro_test <- shapiro.test(residuals)
}

shapiro_result <- data.frame(
  test_statistic = shapiro_test$statistic,
  p_value = shapiro_test$p.value,
  normality_assumption_met = shapiro_test$p.value >= 0.05,
  interpretation = ifelse(shapiro_test$p.value >= 0.05,
                         "Residuals appear normally distributed",
                         "Residuals do not appear normally distributed")
)

kable(shapiro_result, caption = "Normality Test for Residuals (Shapiro-Wilk)", digits = 6) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# QQ plot for residuals
qq_residuals <- ggplot(data.frame(residuals = residuals), aes(sample = residuals)) +
  stat_qq() +
  stat_qq_line() +
  labs(
    title = "QQ Plot of Model Residuals",
    subtitle = "Checking for normality assumption",
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_minimal()

print(qq_residuals)
ggsave("output/figures/qq_residuals.png", qq_residuals, 
       width = 8, height = 6, dpi = 300)
```


Comprehensive Mathematical Summary

```{r}
# 13. COMPREHENSIVE MATHEMATICAL SUMMARY
#------------------------------------------------------
# Create a master summary of all key mathematical findings
mathematical_evidence <- data.frame(
  finding = c(
    "U-Shaped Relationship",
    "Optimal Temperature",
    "Temperature Breakpoints",
    "Regional Differences",
    "ERCO Sensitivity",
    "Seasonal Effect",
    "Predictive Accuracy",
    "Economic Impact"
  ),
  mathematical_evidence = c(
    paste0("Quadratic term coefficient = ", round(coef(quad_model)[3], 2), 
          " (t=", round(summary(quad_model)$coefficients[3,3], 2), 
          ", p<", format.pval(summary(quad_model)$coefficients[3,4], digits = 3), ")"),
    paste0(round(optimal_temp, 1), "°F (95% CI: ", 
          round(inflection_ci$percent[4], 1), "-", 
          round(inflection_ci$percent[5], 1), "°F)"),
    paste0("Lower breakpoint: ", round(breakpoints$Estimate[1], 1), 
          "°F (95% CI: [", round(breakpoints$CI_Lower[1], 1), "°F, ", 
          round(breakpoints$CI_Upper[1], 1), "°F]), ", 
          "Upper breakpoint: ", round(breakpoints$Estimate[2], 1), 
          "°F (95% CI: [", round(breakpoints$CI_Lower[2], 1), "°F, ", 
          round(breakpoints$CI_Upper[2], 1), "°F])"),
    paste0("Interaction F-value = ", round(interaction_anova$`F value`[5], 2), 
          " (p<", format.pval(interaction_anova$`Pr(>F)`[5], digits = 3), ")"),
    paste0("ERCO elasticity = ", round(elasticity_data$elasticity[elasticity_data$energy_region == "ERCO"], 3), 
          " (", round(elasticity_data$elasticity[elasticity_data$energy_region == "ERCO"] / 
                    min(elasticity_data$elasticity), 1), "× higher than least sensitive region)"),
    paste0("Summer demand ", round(seasonal_effects$percent_diff_from_min[seasonal_effects$season == "Summer"] * 100, 1), 
          "% higher than minimum season (p<", 
          format.pval(seasonal_tukey_df$`p adj`[seasonal_tukey_df$comparison == "Summer-Spring"], digits = 3), ")"),
    paste0("Random Forest R² = ", round(model_comparison$r_squared[2], 3), 
          " (", round(model_comparison$percent_improvement[2], 1), "% improvement over linear model)"),
    paste0("Each 1°F deviation from optimal temperature increases demand by ", 
          round(mean(temp_effect_data$pct_change_per_degree, na.rm = TRUE), 2), "%")
  ),
  statistical_test = c(
    "Multiple regression with quadratic term",
    "Bootstrapped confidence intervals (1,000 resamples)",
    "Segmented regression analysis",
    "ANOVA with region×temperature interaction",
    "Temperature elasticity estimation",
    "ANOVA with Tukey HSD post-hoc test",
    "Cross-validation on test dataset",
    "Marginal effects analysis"
  )
)

kable(mathematical_evidence, caption = "COMPREHENSIVE MATHEMATICAL SUMMARY") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  column_spec(2, width = "500px")

# 14. EXECUTIVE SUMMARY
#------------------------------------------------------
executive_summary <- "
# Executive Summary: Weather-Energy Relationship Analysis

## Key Findings

1. **U-Shaped Temperature-Demand Relationship**: Energy demand follows a robust U-shaped pattern with temperature, with significantly higher consumption at both temperature extremes. The relationship is validated by a highly significant quadratic term coefficient of 548.15 (t=34.73, p<1.41e-254) with tight 95% bootstrap CI [517.75, 577.64].

2. **Optimal Temperature Point**: Energy demand reaches its minimum at 51.5°F (95% CI: 50.8-52.2°F), creating an energy efficiency 'sweet spot'. Regional variations in optimal temperature correlate with climate patterns: CISO (California): 41.7°F, NYIS (New York): 50.2°F, ERCO (Texas): 57.5°F.

3. **Temperature Breakpoints**: Energy demand behavior changes significantly at specific temperature thresholds: lower breakpoint at 37.7°F (95% CI: [36.7°F, 38.7°F]) and upper breakpoint at 59.3°F (95% CI: [58.2°F, 59.3°F]), likely corresponding to heating and cooling activation points.

4. **Quantifiable Economic Impact**: Each 1°F deviation from optimal temperature increases energy demand by 2.03% on average, with a progressive pattern: small deviations (0-5°F): 1.91% per degree, medium deviations (15-20°F): 2.18% per degree, large deviations (>30°F): 3.06% per degree.

5. **Regional Sensitivity Variations**: Energy demand sensitivity to temperature varies substantially by region, with highly significant interaction effects (F=2310.80, p<2.2e-16). Florida (FPL) and Arizona (SRP) show the highest elasticity (1.21), while Northwest (BPAT) shows the lowest (0.46).

6. **Seasonal Effects**: Seasonal factors beyond temperature significantly impact energy demand, with summer demand 26.5% above spring baseline. Statistical significance confirmed by Tukey HSD tests (summer-spring difference: +207,417 units, p<1.73e-8).

7. **Superior Predictive Performance**: Advanced statistical methods dramatically outperform simple models: Random Forest achieves R²=0.997 compared to linear regression R²=0.154, representing a 93.1% improvement in predictive accuracy.

## Recommendations

1. **Energy System Design**: Infrastructure planning should accommodate the quantified demand increases at both low and high temperature extremes, with capacity tailored to regional sensitivity patterns.

2. **Efficiency Program Targeting**: Programs should focus on improving efficiency at temperatures below 38°F and above 59°F, where demand increases most rapidly.

3. **Demand Response Optimization**: The identified optimal temperature range (50-52°F) provides an ideal target for demand response programs.

4. **Climate Risk Assessment**: The quantified relationship between temperature deviations and energy demand enables precise climate change impact modeling.

5. **Regional Policy Differentiation**: Policies should be tailored to regional temperature elasticities, with most aggressive interventions in high-elasticity regions.

6. **Forecasting Methodology**: The dramatic superiority of Random Forest models justifies investment in advanced modeling approaches for demand forecasting.

## Technical Details

- Analysis based on large dataset (n=15,609) across major U.S. energy regions
- Statistical significance confirmed through multiple approaches (regression, bootstrapping, ANOVA)
- Robust to diagnostic challenges (heteroskedasticity: BP=777.66, p<1.36e-169)
- Consistent findings across multiple model specifications and estimation approaches
"

# Save executive summary
writeLines(executive_summary, "output/executive_summary.md")
```


Key Insights and Visualizations Dashboard

```{r}
# 15. VISUALIZATIONS DASHBOARD
#------------------------------------------------------
# Create comprehensive dashboard
p1 <- u_shape_plot +
  theme(legend.position = "none", plot.title = element_text(size = 12))
p2 <- importance_plot +
  theme(plot.title = element_text(size = 12))
p3 <- regional_plot +
  theme(legend.position = "none", plot.title = element_text(size = 12))
p4 <- seasonal_ci_plot +
  theme(legend.position = "none", plot.title = element_text(size = 12))

dashboard <- (p1 + p2) / (p3 + p4) +
  plot_annotation(
    title = "Weather-Energy Relationship Analysis Dashboard",
    subtitle = sprintf(
      "Key Findings: U-shaped relationship | Optimal temperature: %.1f°F | Regional variations significant",
      optimal_temp
    ),
    caption = "Source: Analysis of 2024 Weather and Energy Data",
    theme = theme(
      plot.title = element_text(size = 20, face = "bold"),
      plot.subtitle = element_text(size = 14),
      plot.caption = element_text(size = 10)
    )
  )

ggsave("output/figures/analysis_dashboard.png", dashboard, 
       width = 16, height = 12, dpi = 300)

# Create a simplified insights table for reporting
insights <- data.frame(
  Finding = c(
    "U-Shaped Relationship",
    "Temperature Impact",
    "Seasonal Variation",
    "Regional Differences",
    "Weather Sensitivity",
    "Model Performance"
  ),
  Description = c(
    "Energy demand increases at both temperature extremes (below 40°F and above 80°F)",
    "Temperature explains 18.6% of demand variation",
    "Summer demand exceeds winter by 207.4 GWh on average",
    "ERCO (Texas) shows highest weather sensitivity among major regions",
    "Humidity and cloud cover have secondary effects on demand",
    sprintf("Random Forest model achieves R² of %.3f in demand prediction",
            model_comparison$r_squared[2])
  ),
  Evidence = c(
    "Quadratic regression shows significant temp² coefficient (p < 0.001)",
    "Correlation analysis and feature importance rankings",
    "ANOVA and Tukey HSD tests confirm seasonal differences (p < 0.001)",
    "Regional sensitivity analysis and interaction effects",
    "Multiple regression coefficients and partial correlations",
    "Cross-validation results on test dataset"
  )
)

# Save insights
write_csv(insights, "output/key_insights.csv")
kable(insights, caption = "Key Insights Summary") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  column_spec(2, width = "400px")

# Final message
cat("\nComprehensive weather-energy relationship analysis complete.\n")
cat("All results, figures, and reports saved to the output directory.\n")
cat(sprintf("Optimal temperature identified at %.1f°F with significant regional variations.\n", 
            optimal_temp))
cat(sprintf("Each 1°F deviation from optimal temperature increases energy demand by approximately %.2f%%.\n", 
            mean(temp_effect_data$pct_change_per_degree, na.rm = TRUE)))
```
